{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "from gpytorch.kernels import RBFKernel\n",
    "from gpytorch.models import ExactGP\n",
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, kernel):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = kernel\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "likelihood.noise = 1.00\n",
    "\n",
    "k_ard = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=2))\n",
    "k_ard.outputscale = 0.1\n",
    "k_ard.base_kernel.lengthscale = [0.1, 1]\n",
    "\n",
    "kernel = k_ard\n",
    "\n",
    "with open(\"hpo_results_gamma_pos/bayesian_optimization2.json\") as f:\n",
    "    hpo_framework_results = json.loads(f.read())\n",
    "\n",
    "df = pd.DataFrame(hpo_framework_results)\n",
    "df_expanded = pd.json_normalize(df[0])\n",
    "df = pd.concat([df, df_expanded], axis=1)\n",
    "\n",
    "x_features = ['mdp.gamma', 'mdp.reward.position']\n",
    "x_features_names = ['Gamma', 'Reward position weight']\n",
    "x = df[x_features].to_numpy()\n",
    "y = df[1].to_numpy().reshape(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "train_x = torch.from_numpy(x - x.mean(axis=0))\n",
    "train_y = torch.from_numpy((y - y.mean()).ravel())\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.suptitle(f\"\")\n",
    "mlls = {}\n",
    "model = ExactGPModel(train_x, train_y, likelihood, kernel)\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "training_iter = 100\n",
    "for training_i in range(training_iter):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(train_x)\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    if training_i % 20 == 0:\n",
    "        print('Iter %d/%d - Loss: %.3f  outputscale: %.3f lengthscale: %.20s   noise: %.3f' % (\n",
    "            training_i + 1, training_iter, loss.item(),\n",
    "            model.covar_module.outputscale.item(),\n",
    "            str(model.covar_module.base_kernel.lengthscale.detach().numpy()),\n",
    "            model.likelihood.noise.item()\n",
    "        ))\n",
    "    optimizer.step()\n",
    "current_mll = mll(model(train_x), train_y)\n",
    "model.eval()\n",
    "    \n",
    "x1_grid, x2_grid = np.meshgrid(np.linspace(np.min(x[:, 0]), np.max(x[:, 0]), 100), np.linspace(np.min(x[:, 1]), np.max(x[:, 1]), 100))\n",
    "x_test = torch.from_numpy(np.vstack([x1_grid.ravel() - x[:, 0].mean(), x2_grid.ravel() - x[:, 1].mean()]).T)\n",
    "with torch.no_grad():\n",
    "    predictive_dist = model(x_test)\n",
    "z_test = predictive_dist.mean.numpy().reshape(x1_grid.shape) + y.mean()\n",
    "ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "surf = ax.plot_surface(x1_grid, x2_grid, z_test, cmap='viridis', alpha=0.7)\n",
    "# surf = ax.scatter(x1_grid, x2_grid, z_test, cmap='viridis')\n",
    "elev, azim = ax.elev, ax.azim\n",
    "new_azimuth = azim - 180\n",
    "ax.view_init(elev=elev, azim=new_azimuth)\n",
    "ax.set_xlabel(x_features_names[0])\n",
    "ax.set_ylabel(x_features_names[1])\n",
    "ax.set_zlabel('Objective')\n",
    "# ax.set_title(kernel_name)\n",
    "x_min, x_max = 0.90, 1.00\n",
    "y_min, y_max = 0.00, 5\n",
    "z = -1.0\n",
    "ax.plot3D([x_min, x_min], [y_min, y_max], [z, z], color='k')\n",
    "ax.plot3D([x_min, x_max], [y_max, y_max], [z, z], color='k')\n",
    "ax.plot3D([x_max, x_max], [y_max, y_min], [z, z], color='k')\n",
    "ax.plot3D([x_max, x_min], [y_min, y_min], [z, z], color='k')\n",
    "ax.scatter(x[:, 0], x[:, 1], y.ravel())\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"figures/gamma-pos-predictive.png\", dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[(df[\"mdp.gamma\"] > x_min) & (df[\"mdp.gamma\"] < x_max) & (df[\"mdp.reward.position\"] > y_min) & (df[\"mdp.reward.position\"] < y_max)]\n",
    "\n",
    "plt.hist(filtered_df[1], bins=50)\n",
    "plt.xlabel(\"Objective\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.savefig(f\"figures/gamma-pos-relevant-histogram.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
